{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLUNT2mlKW5St34hW4i99a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranay8297/fastaip2/blob/main/pre_act_experimentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIxOUIMkahEZ",
        "outputId": "278178d9-c369-410b-f8c6-d2c898aa2180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16\n",
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from ipdb) (2.0.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.13)\n",
            "Installing collected packages: jedi, ipdb\n",
            "Successfully installed ipdb-0.13.13 jedi-0.19.1\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.10.0)\n",
            "Installing collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for miniai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.26.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.27.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.1.0\n",
        "!pip install datasets\n",
        "!pip install ipdb\n",
        "!pip install torcheval\n",
        "!pip install -Uqq git+https://github.com/fastai/course22p2\n",
        "!pip install diffusers\n",
        "!pip install tqdm\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "import numpy as np\n",
        "import fastcore.all as fc\n",
        "import matplotlib as mpl, matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from scipy.linalg import sqrtm\n",
        "from functools import partial\n",
        "from ipdb import set_trace as st\n",
        "\n",
        "from datasets import load_dataset\n",
        "from diffusers import UNet2DModel\n",
        "from accelerate import Accelerator\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch import autocast\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.cuda.amp import GradScaler\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision.transforms.functional import to_tensor, resize\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import v2, InterpolationMode\n",
        "from torcheval.metrics import MulticlassAccuracy\n",
        "\n",
        "from miniai.datasets import *\n",
        "from miniai.learner import *\n",
        "from miniai.augment import *\n",
        "from miniai.activations import *\n",
        "from miniai.init import *\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "mpl.rcParams['image.cmap'] = 'gray_r'\n",
        "\n",
        "# set_seed(42)\n",
        "mdl_path = Path('drive/MyDrive/fastai_p2/models/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnkLMDuVaqEt",
        "outputId": "0ba6f033-beef-4766-ba66-89d5f6eefed7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "tafCNz8fcxki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(some):\n",
        "  x, y = zip(*some)\n",
        "  return torch.stack(x, dim = 0), torch.stack(y, dim = 0)\n",
        "\n",
        "class TinyImagenetDS:\n",
        "  def __init__(self, im_paths, labels):\n",
        "    fc.store_attr()\n",
        "    self.tfm = transforms.ToTensor()\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return transforms.ToTensor()(Image.open(self.im_paths[idx])), torch.tensor(self.labels[idx])\n",
        "\n",
        "  def __len__(self): return len(self.im_paths)\n",
        "\n",
        "class AveragePool(nn.Module):\n",
        "  def forward(self, x): return x.mean((-1, -2))\n",
        "\n",
        "def conv(ni, nf, stride = 2, ks = 3, act = GeneralRelu, norm = None, bias = True):\n",
        "  layers = [nn.Conv2d(ni, nf, kernel_size = ks, stride = stride, padding = ks//2, bias = bias)]\n",
        "  if act: layers.append(act())\n",
        "  if norm: layers.append(norm(nf) if norm.__name__ in (\"BatchNorm2d\", \"BatchNorm1d\", \"BatchNorm3d\") else norm()) # else its a batch norm.\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, ni, nf, stride = 2, ks = 3, norm = nn.BatchNorm2d, act = GeneralRelu):\n",
        "    super().__init__()\n",
        "    fc.store_attr()\n",
        "    self.create_id()\n",
        "    self.create_playground()\n",
        "    self.act_fn = act()\n",
        "\n",
        "  def create_id(self):\n",
        "    self.id_conv = fc.noop if self.ni == self.nf and self.stride == 1 else conv(self.ni, self.nf, stride = 1, ks = 1, norm = None, act = None)\n",
        "    self.avg_pool = fc.noop if self.stride == 1 else nn.AvgPool2d(2, ceil_mode = True)\n",
        "\n",
        "  def conserve(self, x): return self.id_conv(self.avg_pool(x))\n",
        "\n",
        "  def create_playground(self):\n",
        "    layers = [\n",
        "        conv(self.ni, self.nf, stride = 1, norm = self.norm, act = self.act),\n",
        "        conv(self.nf, self.nf, stride = self.stride, norm = self.norm, act = self.act),\n",
        "    ]\n",
        "    self.convs = nn.Sequential(*layers)\n",
        "    self.pf = conv(self.nf, self.nf, stride = 1, act = self.act, norm = self.norm)\n",
        "    if self.norm:\n",
        "      nn.init.constant_(self.pf[-1].weight, 0.)\n",
        "\n",
        "  def play(self, x):\n",
        "    inter = self.convs(x)\n",
        "    return  inter + self.pf(inter)\n",
        "\n",
        "  def forward(self, x): return self.act_fn(self.conserve(x) + self.play(x))\n",
        "\n",
        "  def __name__(self):\n",
        "    return 'ResBlock'\n",
        "\n",
        "class ResBlockV2(ResBlock):\n",
        "\n",
        "  def forward(self, x): return self.conserve(x) + self.act_fn(self.play(x))\n",
        "\n",
        "  def __name__(self):\n",
        "    return 'ResBlockV2'\n",
        "\n",
        "class ResBlockDV2(ResBlock):\n",
        "\n",
        "  def __init__(self, ni, nf, stride = 2, ks = 3, norm = nn.BatchNorm2d, act = GeneralRelu, p = 0.1, dropout_func = nn.Dropout2d(0.2)):\n",
        "    super().__init__(ni, nf, stride = 2, ks = 3, norm = nn.BatchNorm2d, act = act)\n",
        "    self.drop = dropout_func\n",
        "\n",
        "  def forward(self, x): return self.drop(super().forward(x))\n",
        "\n",
        "  def __name__(self):\n",
        "    return 'ResBlockD'\n",
        "\n",
        "\n",
        "class ResBlockDV3(ResBlockV2):\n",
        "\n",
        "  def __init__(self, ni, nf, stride = 2, ks = 3, norm = nn.BatchNorm2d, act = GeneralRelu, p = 0.1, dropout_func = nn.Dropout2d(0.2)):\n",
        "    super().__init__(ni, nf, stride = 2, ks = 3, norm = nn.BatchNorm2d, act = act)\n",
        "    self.drop = dropout_func\n",
        "\n",
        "  def forward(self, x): return self.drop(super().forward(x))\n",
        "\n",
        "  def __name__(self):\n",
        "    return 'ResBlockD'\n",
        "\n",
        "class UnetModel(UNet2DModel):\n",
        "  def forward(self, x): return super().forward(*x).sample\n",
        "\n",
        "class BaseSchedulerCB(Callback):\n",
        "  def __init__(self, sched_class): self.sched_class = sched_class\n",
        "  def before_fit(self, learn): self.sched = self.sched_class(learn.opt)\n",
        "  def step(self, learn):\n",
        "    if not learn.training: return\n",
        "    self.sched.step()\n",
        "\n",
        "class BatchSchedulerCB(BaseSchedulerCB):\n",
        "  def __init__(self, sched_class):super().__init__(sched_class)\n",
        "  def after_batch(self, learn): self.step(learn)\n",
        "\n",
        "class AccLearner(TrainLearner):\n",
        "\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.aclr = Accelerator()\n",
        "    self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
        "    self.model, self.opt, self.dls.train, self.dls.valid = self.aclr.prepare(self.model, self.opt, self.dls.train, self.dls.valid)\n",
        "\n",
        "  def backward(self): self.aclr.backward(self.loss)\n",
        "\n",
        "class LRScheduler:\n",
        "  def __init__(self):\n",
        "    self.batch_count = 0\n",
        "\n",
        "  def step(self):\n",
        "    raise NotImplementedError()\n",
        "\n",
        "class DropoutScheduler(LRScheduler):\n",
        "  def __init__(self, epochs = 10, min = 0.2, max = 0.5):\n",
        "    self.drops = iter(torch.linspace(min, max, steps = epochs))\n",
        "\n",
        "  def step(self):\n",
        "    return next(self.drops)\n",
        "\n",
        "class DropoutCB(Callback):\n",
        "  def __init__(self, drop_sched): fc.store_attr()\n",
        "  def before_epoch(self, learn):\n",
        "    if not learn.training: return\n",
        "    p = self.drop_sched.step()\n",
        "    for block in learn.model:\n",
        "      if isinstance(block, ResBlockDV2): block.drop.p = p\n",
        "      if isinstance(block, (nn.Dropout, nn.Dropout2d)): block.p = p"
      ],
      "metadata": {
        "id": "LaPktDBYbqIY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_conv(ni, nf, stride = 2, ks = 3, act = GeneralRelu, norm = None, bias = True):\n",
        "  layers = []\n",
        "  if act: layers.append(act())\n",
        "  if norm: layers.append(norm(ni) if norm.__name__ in (\"BatchNorm2d\", \"BatchNorm1d\", \"BatchNorm3d\") else norm()) # else its a layer norm.\n",
        "  layers.append(nn.Conv2d(ni, nf, kernel_size = ks, stride = stride, padding = ks//2, bias = bias))\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        "class PreActResBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, ni, nf, stride = 2, ks = 3, norm = nn.BatchNorm2d, act = GeneralRelu):\n",
        "    super().__init__()\n",
        "    fc.store_attr()\n",
        "    self.create_id()\n",
        "    self.create_playground()\n",
        "    self.act_fn = act()\n",
        "\n",
        "  def create_id(self):\n",
        "    self.id_conv = fc.noop if self.ni == self.nf and self.stride == 1 else conv(self.ni, self.nf, stride = 1, ks = 1, norm = None, act = None)\n",
        "    self.avg_pool = fc.noop if self.stride == 1 else nn.AvgPool2d(2, ceil_mode = True)\n",
        "\n",
        "  def conserve(self, x): return self.id_conv(self.avg_pool(x))\n",
        "\n",
        "  def create_playground(self):\n",
        "    layers = [\n",
        "        pre_conv(self.ni, self.nf, stride = 1, norm = self.norm, act = self.act),\n",
        "        pre_conv(self.nf, self.nf, stride = self.stride, norm = self.norm, act = self.act),\n",
        "    ]\n",
        "    self.convs = nn.Sequential(*layers)\n",
        "    self.pf = pre_conv(self.nf, self.nf, stride = 1, act = self.act, norm = self.norm)\n",
        "    if self.norm:\n",
        "      nn.init.constant_(self.pf[-1].weight, 0.)\n",
        "\n",
        "  def play(self, x):\n",
        "    inter = self.convs(x)\n",
        "    return  inter + self.pf(inter)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conserve(x) + self.play(x)\n",
        "\n",
        "  def __name__(self):\n",
        "    return 'PreResBlock'\n",
        "\n",
        "class PreActResBlockD(PreActResBlock):\n",
        "\n",
        "  def __init__(self, ni, nf, stride = 2, ks = 3, norm = nn.BatchNorm2d, act = GeneralRelu, p = 0.1, dropout_func = nn.Dropout2d(0.2)):\n",
        "    super().__init__(ni, nf, stride = 2, ks = 3, norm = nn.BatchNorm2d, act = act)\n",
        "    self.drop = dropout_func\n",
        "\n",
        "  def forward(self, x): return self.drop(super().forward(x))\n",
        "\n",
        "  def __name__(self):\n",
        "    return 'ResBlockD'\n",
        "\n",
        "class AugmentNormCB(Callback):\n",
        "  order = 20\n",
        "  def __init__(self, transforms = None):\n",
        "    fc.store_attr()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    self.mean = torch.tensor([0.4810, 0.4482, 0.3968], device = device)\n",
        "    self.std = torch.tensor([0.2760, 0.2683, 0.2813], device = device)\n",
        "    if not self.transforms:\n",
        "      self.transforms = v2.Compose([\n",
        "          v2.RandomHorizontalFlip(p = 0.5),\n",
        "          v2.RandomPerspective(distortion_scale=0.2, p=0.8),\n",
        "          RandErase(0.2)\n",
        "      ])\n",
        "\n",
        "  def before_batch(self, learn):\n",
        "    if learn.training: learn.batch = (self.transforms(learn.batch[0]), learn.batch[1])\n",
        "    x = learn.batch[0]\n",
        "    x = (x - self.mean[None, :, None, None])/(self.std[None, :, None, None])\n",
        "    learn.batch = (x, learn.batch[1])\n",
        "\n",
        "class AugmentNormCBV2(AugmentNormCB):\n",
        "  def __init__(self, total_epochs, threshold = 0.1, initial_transforms = [], addtional_transforms = []):\n",
        "    fc.store_attr()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    self.mean = torch.tensor([0.47565, 0.40303, 0.31555], device = device)\n",
        "    self.std = torch.tensor([0.28858, 0.24402, 0.26615], device = device)\n",
        "    self.transforms = v2.Compose(self.initial_transforms)\n",
        "    self.task_done = False\n",
        "\n",
        "  def before_epoch(self, learn):\n",
        "    if (learn.epoch >= self.total_epochs*self.threshold) and self.task_done == False:\n",
        "      self.transforms = v2.Compose(self.initial_transforms + self.addtional_transforms)\n",
        "      self.task_done = True\n",
        "\n",
        "def init_weights(m, leaky = 0.):\n",
        "  if isinstance(m, (nn.Conv2d, nn.Conv1d, nn.Conv3d, nn.Linear)): nn.init.kaiming_normal_(m.weight, a = leaky)\n",
        "\n",
        "iw = partial(init_weights, leaky = 0.1)"
      ],
      "metadata": {
        "id": "2B0x07uncClD"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
        "!unzip tiny-imagenet-200.zip"
      ],
      "metadata": {
        "id": "c82zK14QcD9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep"
      ],
      "metadata": {
        "id": "Sg5KK_Ggc1r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfm = transforms.ToTensor()\n",
        "\n",
        "def _verify_im_path(im_path):\n",
        "  im = Image.open(im_path)\n",
        "  im_t = tfm(im)\n",
        "  del im\n",
        "  if im_t.shape[0] == 1: return False\n",
        "  return True\n",
        "\n",
        "def verify_ims(im_paths):\n",
        "  verified_paths = []\n",
        "  for i in im_paths:\n",
        "    if _verify_im_path(i): verified_paths.append(i)\n",
        "  return verified_paths\n",
        "\n",
        "def get_train_d(path, limit = None):\n",
        "  im_paths, classes = [], []\n",
        "  for i in tqdm(path.ls()):\n",
        "    cla = i.name\n",
        "    ps = (i/'images').ls()\n",
        "    if limit != None: ps = ps[:limit]\n",
        "    ims = verify_ims(ps)\n",
        "    im_paths += ims\n",
        "    classes += [cla]*len(ims)\n",
        "  return im_paths, classes\n",
        "\n",
        "def get_valid_d(path):\n",
        "  paths, classes = [], []\n",
        "  with open(path/\"val_annotations.txt\", 'r') as f:\n",
        "    for i in tqdm(f.read().splitlines()):\n",
        "      im_path = path/'images'/i.split()[0]\n",
        "      if _verify_im_path(im_path):\n",
        "        paths.append(im_path)\n",
        "        classes.append(i.split()[1])\n",
        "  return paths, classes"
      ],
      "metadata": {
        "id": "1h3DdEOucKRS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_im_paths, train_labels = get_train_d(Path('tiny-imagenet-200/train'), limit = 50)\n",
        "valid_paths, valid_classes = get_valid_d(Path('tiny-imagenet-200/val'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmXW59YMcTzT",
        "outputId": "2c319a44-adb4-4693-a92f-fc12e698f1f4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:04<00:00, 43.30it/s]\n",
            "100%|██████████| 10000/10000 [00:06<00:00, 1569.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_dict = {v: i for i, v in enumerate(set(train_labels))}\n",
        "new_train_labels = tuple(map(lambda x: class_dict[x], train_labels))\n",
        "new_valid_labels = tuple(map(lambda x: class_dict[x], valid_classes))"
      ],
      "metadata": {
        "id": "PLetFohacZu-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyImagenetDS:\n",
        "  def __init__(self, im_paths, labels):\n",
        "    fc.store_attr()\n",
        "    self.tfm = transforms.ToTensor()\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return transforms.ToTensor()(Image.open(self.im_paths[idx])), torch.tensor(self.labels[idx])\n",
        "\n",
        "  def __len__(self): return len(self.im_paths)"
      ],
      "metadata": {
        "id": "tIQeAlwncbZW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TinyImagenetDS(train_im_paths, new_train_labels)\n",
        "valid_ds = TinyImagenetDS(valid_paths, new_valid_labels)\n",
        "len(train_ds), len(valid_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnRnZgMfccxU",
        "outputId": "e3a6e1eb-8a99-43ec-ac24-9ccebd0c4239"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9806, 9832)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/fastai_p2/tiny_img_net/dls/train_ds_exp.pkl', 'wb') as f:\n",
        "  pickle.dump(train_ds, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/fastai_p2/tiny_img_net/dls/valid_ds_exp.pkl', 'wb') as f:\n",
        "  pickle.dump(valid_ds, f)"
      ],
      "metadata": {
        "id": "a6e-r_zWdDuf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(some):\n",
        "  x, y = zip(*some)\n",
        "  return torch.stack(x, dim = 0), torch.stack(y, dim = 0)"
      ],
      "metadata": {
        "id": "VUOZNFejcqDS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl, valid_dl = DataLoader(train_ds, 256, True, collate_fn = collate_fn, num_workers = 2), DataLoader(valid_ds, 256, True, collate_fn = collate_fn, num_workers = 2)"
      ],
      "metadata": {
        "id": "VHJlnevxcrhr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments with Modeling."
      ],
      "metadata": {
        "id": "LR8RFq27dUpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(train_dl))"
      ],
      "metadata": {
        "id": "vxFChRkudfVN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1jya66sdhfd",
        "outputId": "610efae4-bf37-4c49-8ca9-a7ca1b2a60ce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 3, 64, 64]), torch.Size([256]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check in lr scheduler after what epoch learning rate reduces - 0.3*total_steps\n",
        "# Experiment with adding higher transforms after epoch 0.1*total_steps and 0.3*total_steps.\n",
        "# Check the models activation functions - get it general relu with right amount of leak - Build the model - Refactor the code\n",
        "    # Blocks Required:- Pre Act Resblocks, Dropout versions of pre act resblocks, function to build model with nfs and nls - done\n",
        "# Make the network more deeper and more layers at each level - done\n",
        "# Re factor the code properly. - done\n",
        "\n",
        "# Just complete Aug Norm CB v2"
      ],
      "metadata": {
        "id": "6wszuxQMdiN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to build model with nfs and nls\n",
        "\n",
        "def blocks(nls, ni, nf, block):\n",
        "  ls = [PreActResBlock(ni, nf)] + [block(nf, nf, stride = 1) for i in range(nls - 1)]\n",
        "  return ls\n",
        "\n",
        "def get_model(block = PreActResBlockD, act = GeneralRelu, nls = [2, 3, 4, 2, 1], nfs = [64, 128, 256, 512, 1024], nc = 10, norm = nn.BatchNorm2d, bias = True, p = 0.2):\n",
        "\n",
        "  pnf, layers = 3, []\n",
        "\n",
        "  for nl, nf in zip(nls, nfs):\n",
        "    layers += blocks(nl, pnf, nf, block)\n",
        "    pnf = nf\n",
        "\n",
        "  return nn.Sequential(*layers, act(), AveragePool(), nn.Dropout(p), nn.Linear(nf, nc, bias = False), nn.BatchNorm1d(nc))"
      ],
      "metadata": {
        "id": "25yBFyCKjVE-"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_gr = partial(GeneralRelu, sub = 0.1, leak = 0.1)\n",
        "iw = partial(init_weights, leaky = 0.1)"
      ],
      "metadata": {
        "id": "VcGasPwgkbUb"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls = DataLoaders(train_dl, valid_dl)\n",
        "lr_max, epochs = 5e-02, 100\n",
        "cbs = [\n",
        "          DeviceCB(torch.device('cuda' if torch.cuda.is_available() else 'cpu')),\n",
        "          MetricsCB(accuracy = MulticlassAccuracy()),\n",
        "          ProgressCB(plot = True),\n",
        "          BatchSchedulerCB(partial(lr_scheduler.OneCycleLR, max_lr = lr_max, epochs = epochs, steps_per_epoch = len(dls.train))),\n",
        "          AugmentNormCBV2(total_epochs = epochs, threshold = 0.31,\n",
        "                          initial_transforms = [v2.RandomHorizontalFlip(p = 0.5),\n",
        "                                                v2.Pad(4),\n",
        "                                                v2.RandomCrop(size=(64, 64)),\n",
        "                                                v2.TrivialAugmentWide(interpolation = InterpolationMode.BILINEAR)],\n",
        "                          addtional_transforms=[RandErase(max_num = 4)]\n",
        "                          )\n",
        "      ]\n",
        "model = get_model(act = act_gr, nls = [2, 3, 8, 5, 2, 1], nfs = [64, 128, 256, 512, 1024, 2048], nc = 200, norm = nn.BatchNorm2d, bias = True, p = 0.25)\n",
        "learner = AccLearner(model, dls, loss_func = nn.CrossEntropyLoss(), lr = lr_max, cbs = cbs, opt_func = torch.optim.AdamW)\n",
        "learner.fit(epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "896aTUXelfQw",
        "outputId": "2752c69a-b180-4174-cfc5-5323583c61df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='6' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      6.00% [6/100 04:58&lt;1:17:53]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>epoch</th>\n",
              "      <th>train</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0.006</td>\n",
              "      <td>5.416</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0.005</td>\n",
              "      <td>30.834</td>\n",
              "      <td>0</td>\n",
              "      <td>eval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0.010</td>\n",
              "      <td>5.360</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0.011</td>\n",
              "      <td>5.613</td>\n",
              "      <td>1</td>\n",
              "      <td>eval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0.009</td>\n",
              "      <td>5.284</td>\n",
              "      <td>2</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0.010</td>\n",
              "      <td>5.312</td>\n",
              "      <td>2</td>\n",
              "      <td>eval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0.012</td>\n",
              "      <td>5.236</td>\n",
              "      <td>3</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0.012</td>\n",
              "      <td>5.546</td>\n",
              "      <td>3</td>\n",
              "      <td>eval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0.013</td>\n",
              "      <td>5.219</td>\n",
              "      <td>4</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0.014</td>\n",
              "      <td>5.389</td>\n",
              "      <td>4</td>\n",
              "      <td>eval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0.013</td>\n",
              "      <td>5.165</td>\n",
              "      <td>5</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0.016</td>\n",
              "      <td>5.115</td>\n",
              "      <td>5</td>\n",
              "      <td>eval</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "      <progress value='28' class='' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      71.79% [28/39 00:31&lt;00:12 5.146]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = 0\n",
        "for i in model.parameters(): t+= i.numel()"
      ],
      "metadata": {
        "id": "MUWjvnh5mkpg"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "berh6vm_2GJ-",
        "outputId": "f349ea28-b088-423b-ed0f-d0d982fb706d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48060182"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZWYfk7y2Iu_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}