{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf4SzZZk1k++/RoWsVagx4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranay8297/fastaip2/blob/main/ml_coding_interview_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Micrograd"
      ],
      "metadata": {
        "id": "xIyiiIDFMhnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "bXqQT21Q_pNE"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "8Gdx0OTZeraI"
      },
      "outputs": [],
      "source": [
        "# Lets start with Micro grad\n",
        "\n",
        "class Value:\n",
        "\n",
        "    def __init__(self, val, parents = (), op = None, label = None):\n",
        "        self.val = val\n",
        "        self.parents = parents\n",
        "        self.op = op\n",
        "        self.grad = 0\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'Value: {self.val:.4f}' + (f'  :: Label: {self.label}' if self.label != None else '')\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        return self + (-other)\n",
        "\n",
        "    def __neg__(self):\n",
        "        return self * -1\n",
        "\n",
        "    def __radd__(self, other):\n",
        "        return self + other\n",
        "\n",
        "    def __rmul__(self, other):\n",
        "        return self * other\n",
        "\n",
        "    def __truediv__(self, other):\n",
        "        return self * (other**-1)\n",
        "\n",
        "    def __add__(self, other):\n",
        "\n",
        "        if not isinstance(other, Value): other = Value(other, label = str(other))\n",
        "\n",
        "        out = Value(self.val + other.val, (self, other), label = f'{self.label}+{other.label}')\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += 1 * out.grad\n",
        "            other.grad += 1 * out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        if not isinstance(other, Value): other = Value(other, label = str(other))\n",
        "        out = Value(self.val * other.val, (self, other), label = f'{self.label}*{other.label}')\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += other.val * out.grad\n",
        "            other.grad += self.val * out.grad\n",
        "\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def __pow__(self, pow):\n",
        "        out = Value(self.val ** pow, (self,), label = f'{self.label}**{pow}')\n",
        "        def _backward():\n",
        "            self.grad += pow*self.val**(pow-1) * out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def exp(self):\n",
        "        exp = np.exp(self.val)\n",
        "        out = Value(exp, (self,), label = f'exp({self.label})')\n",
        "        def _backward():\n",
        "            self.grad += exp * out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def relu(self):\n",
        "        out = Value(self.val if self.val > 0 else 0, label = f'relu({self.label})')\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += 0 if out.val else out.grad\n",
        "\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def backward(self):\n",
        "        self.grad = 1.\n",
        "        visited = set()\n",
        "        dfs = []\n",
        "        # breakpoint()\n",
        "        def _dfs(node):\n",
        "\n",
        "            if node in visited: return\n",
        "\n",
        "            visited.add(node)\n",
        "\n",
        "            for i in node.parents:\n",
        "                _dfs(i)\n",
        "\n",
        "            dfs.append(node)\n",
        "\n",
        "        _dfs(self)\n",
        "        topsort = reversed(dfs)\n",
        "\n",
        "        for i in topsort:\n",
        "            if not hasattr(i, '_backward'): continue\n",
        "            i._backward()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1, x2 = Value(-1.5, label = 'x1'), Value(1.3, label = 'x2')\n",
        "w1, w2 = Value(4, label = 'w1'), Value(5, label = 'w2')\n",
        "b = Value(0, label = 'b')\n",
        "z = w1*x1 + w2*x2 + b\n",
        "z.label = 'z'\n",
        "\n",
        "# z.backward()\n",
        "# w1.grad, w2.grad, b.grad\n",
        "print(z)\n",
        "yhat = ((2*z).exp() - 1)/((2*z).exp() + 1)\n",
        "# yhat.label = 'yhat'\n",
        "print(yhat)\n",
        "\n",
        "yhat.backward()\n",
        "\n",
        "yhat.grad, z.grad, w1.grad, w2.grad, b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2d0W0kJ5cWA",
        "outputId": "c3ef32d5-c2d1-497b-f55f-38f93b3e3f6f"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value: 0.5000  :: Label: z\n",
            "Value: 0.4621  :: Label: exp(z*2)+-1*exp(z*2)+1**-1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0,\n",
              " 0.7864477329659272,\n",
              " -1.1796715994488909,\n",
              " 1.0223820528557053,\n",
              " 0.7864477329659272)"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Module:\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "class Neuron(Module):\n",
        "    def __init__(self, n_in):\n",
        "        self.ws = [Value(random.uniform(-1, 1)) for _ in range(n_in)]\n",
        "        self.b = Value(0)\n",
        "\n",
        "    def forward(self, x): # dot product + b: wx + b\n",
        "        # breakpoint()\n",
        "        return sum((a * b for a, b in zip(self.ws, x))) + self.b\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Neuron containing: {self.ws}\"\n",
        "\n",
        "class Layer(Module):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        # n_in: number of inputs\n",
        "        # n_out: number of outputs desired in a layer\n",
        "        self.neurons = [Neuron(n_in) for _ in range(n_out)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        return [n(x) for n in self.neurons]\n",
        "\n",
        "    def __repr__(self): return f\"Layer containing weights of shape: {len(self.neurons)}x{len(self.neurons[0].ws)}\"\n",
        "\n",
        "\n",
        "class MLP(Module):\n",
        "\n",
        "    def __init__(self, lc = [], act = 'relu'):\n",
        "        # assume lc - layer_config has n_in preppended\n",
        "        self.layers = [Layer(lc[i-1], lc[i]) for i in range(1, len(lc))]\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def __repr__(self):\n",
        "        st = ''\n",
        "        for i in self.layers:\n",
        "            st += i.__repr__() + ' \\n'\n",
        "        return st"
      ],
      "metadata": {
        "id": "YlIK6eZ_vsqO"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [Value(1, label = 'x1'), Value(1.5, label = 'x2'), Value(1.2, label = 'x3')]\n",
        "neu = Neuron(3)\n",
        "neu(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv1wZC7lXFhv",
        "outputId": "88c456c4-aa36-42d5-980f-a0b92b887707"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value: -1.1044  :: Label: None*x1+0+None*x2+None*x3+None"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [Value(1, label = 'x1'), Value(1.5, label = 'x2'), Value(1.2, label = 'x3')]\n",
        "layer = Layer(3, 2)\n",
        "inter = layer(x)\n",
        "inter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKorQi6YvTDJ",
        "outputId": "30699cc9-0552-4fe7-ad76-471375f8b13d"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Value: 1.2700  :: Label: None*x1+0+None*x2+None*x3+None,\n",
              " Value: 1.3024  :: Label: None*x1+0+None*x2+None*x3+None]"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [Value(1, label = 'x1'), Value(1.5, label = 'x2'), Value(1.2, label = 'x3')]\n",
        "mlp = MLP((3, 2, 1))\n",
        "yhat = mlp(x)"
      ],
      "metadata": {
        "id": "BDlts59jzruj"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat[0].backward()\n",
        "yhat[0].val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdcRQehVRuSG",
        "outputId": "6c21dfee-d9e0-4325-e87f-efa04c59558a"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.13525551427592739"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in mlp.layers:\n",
        "    for neu in layer.neurons:\n",
        "        print([i.grad for i in neu.ws])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukRREvcE0ehM",
        "outputId": "c8c2780a-9099-4a2a-91ca-b2965ab5f88d"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.29952624858971144, 0.44928937288456716, 0.3594314983076537]\n",
            "[-0.5134056657947423, -0.7701084986921135, -0.6160867989536908]\n",
            "[-0.5655506771842844, -0.06650054863652788]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch norm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class BN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_filters):\n",
        "        super().__init__()\n",
        "        self.running_mean = None\n",
        "        self.running_std = None\n",
        "\n",
        "        self.scale = nn.Parameter(torch.tensor(1.))\n",
        "        self.shift = nn.Parameter(torch.tensor(0.))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape - bs, ch, h, w\n",
        "        mean = x.mean((0, 1)).squeeze() #bs, h, w\n",
        "        std = x.std((0, 1)).squeeze() #bs, h, w\n",
        "        return self.scale*((x - mean)/std) + self.shift"
      ],
      "metadata": {
        "id": "NhF_apPQVDpN"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bn = BN(4)\n",
        "x = torch.randn(16, 4, 32, 32)\n",
        "out = bn(x)\n",
        "out.shape, out.mean(), out.std()"
      ],
      "metadata": {
        "id": "BZl0LizLaYRe",
        "outputId": "6117c698-ece9-421c-8468-30ca2a19ba39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 4, 32, 32]),\n",
              " tensor(-5.0204e-10, grad_fn=<MeanBackward0>),\n",
              " tensor(0.9922, grad_fn=<StdBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.eye(3)"
      ],
      "metadata": {
        "id": "19nMHoi8lSv6",
        "outputId": "81135166-c213-4bde-886c-aac2a9fd0627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax():\n",
        "    def __init__(self): pass\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.x = x\n",
        "        x_exp = np.exp(x)\n",
        "        x_exp_sum = x_exp.sum()\n",
        "\n",
        "        self.es = x_exp/x_exp_sum\n",
        "        return self.es\n",
        "\n",
        "    def _backward(self):\n",
        "        lsp, rsp = self.es, (np.eye(len(self.x)) - self.es).T\n",
        "        return np.dot(lsp, rsp)"
      ],
      "metadata": {
        "id": "VNgc4lYeuqQM"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [0.14, 0.5, -0.8]\n",
        "soft = Softmax()\n",
        "es = soft(x)"
      ],
      "metadata": {
        "id": "2n5wWQalw1LQ"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es, es.sum()"
      ],
      "metadata": {
        "id": "yT5ZEA8sxSuU",
        "outputId": "fbcaa481-89bb-48d7-cc0c-1c3748aeb417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.35411301, 0.50756059, 0.1383264 ]), 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_grad = soft._backward()"
      ],
      "metadata": {
        "id": "e59Yj1enxTSC"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_grad"
      ],
      "metadata": {
        "id": "tnmmIwnSxzjJ",
        "outputId": "ea4fefed-88d8-467d-a69d-e29903d70bd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04803496,  0.10541262, -0.26382157])"
            ]
          },
          "metadata": {},
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HuUnIVfqyPPr",
        "outputId": "7f4b8a69-0a6b-4637-ce07-3d44e98bc4df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xx = torch.tensor(x, requires_grad = True)\n",
        "y = F.softmax(xx)\n",
        "\n",
        "y.sum().backward()"
      ],
      "metadata": {
        "id": "xfaUl0PvxZTL",
        "outputId": "bb1754a6-e770-445a-eb44-449b8dc98575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-348-bf3ebf7fce68>:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y = F.softmax(xx)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xx, xx.grad"
      ],
      "metadata": {
        "id": "BzJ3G3xWxhtb",
        "outputId": "ca13d1c4-170a-4ca4-b9ca-2c8d3c57d03b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.1400,  0.5000, -0.8000], requires_grad=True),\n",
              " tensor([2.1107e-08, 3.0253e-08, 8.2449e-09]))"
            ]
          },
          "metadata": {},
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron and othe blocks from scratch (Dealing with matrices)"
      ],
      "metadata": {
        "id": "2tIlAx1XMkgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jQbHPRgXy7hT"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataset of 20 examples\n",
        "# 3xs and 1ys\n",
        "# create a ws and b\n",
        "# sigmoid\n",
        "# mse"
      ],
      "metadata": {
        "id": "2Xc9mCoaMtN-"
      },
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(yhat, y):\n",
        "    return np.mean((yhat-y)**2)\n",
        "\n",
        "def mse_grad(yhat, y):\n",
        "    return (2/len(yhat))*(yhat - y)\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1/(1 + np.exp(-z))\n",
        "\n",
        "def sigmoid_grad(act):\n",
        "    return act*(1 - act)\n",
        "\n",
        "def relu(z):\n",
        "    return z * (z > 0)\n",
        "\n",
        "def relu_grad(z):\n",
        "    return (z > 0)\n",
        "\n",
        "def softmax(z):\n",
        "    exp_sum = np.exp(z).sum(-1)\n",
        "    return np.exp(z)/np.expand_dims(exp_sum, axis=1)\n",
        "\n",
        "def softmax_grad(acts):\n",
        "    return acts * (1. - acts)\n",
        "\n",
        "def cross_entropy(yhat, y):\n",
        "    return y * -1 * np.log(yhat)\n",
        "\n",
        "def cross_entropy_grad(yhat, y):\n",
        "    return y * (-1/yhat)"
      ],
      "metadata": {
        "id": "IA-PQ8yYdRIv"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ys = np.arange(0, 1, 1/20)\n",
        "\n",
        "ys = np.random.uniform(low=0, high=1., size=(20,2))\n",
        "xs = np.random.uniform(low= -1, high = 2, size = (20, 3))\n",
        "\n",
        "# 3x2 matrix for 3 inputs and 2 outputs\n",
        "ws = np.random.uniform(low = -1, high = 1, size = (3, 2))\n",
        "bs = np.zeros((2))\n",
        "# xs.shape, ys.shape, ws.shape, bs.shape\n",
        "\n",
        "zs = xs.dot(ws) + bs\n",
        "yhat = sigmoid(zs)\n",
        "print(yhat.shape)\n",
        "\n",
        "loss = mse(yhat, y)\n",
        "print(\"Loss: \", loss)\n",
        "\n",
        "dl_dyhat = mse_grad(yhat, y)\n",
        "dyhat_dz = sigmoid_grad(yhat)\n",
        "# dyhat_dz.shape\n",
        "dl_dz = dyhat_dz * dl_dyhat\n",
        "dl_dw = (1/xs.shape[0])*np.dot(xs.T, dl_dz)\n",
        "\n",
        "lr = 0.5\n",
        "ws += -lr*dl_dw\n",
        "bs += -lr*dl_dz.mean(0)"
      ],
      "metadata": {
        "id": "Rt19kyD1drUi",
        "outputId": "336a00c3-3f92-4cf6-d94e-3380e84ee6a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 2)\n",
            "Loss:  0.243156526893116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(xs, ys, n_epochs = 100):\n",
        "\n",
        "    lr = 0.7\n",
        "    # 3x2 matrix for 3 inputs and 2 outputs\n",
        "    ws = np.random.uniform(low = -1, high = 1, size = (xs.shape[1], ys.shape[1]))\n",
        "    bs = np.zeros((ys.shape[1]))\n",
        "    print(xs.shape, ys.shape, ws.shape, bs.shape)\n",
        "\n",
        "    for i in range(n_epochs):\n",
        "\n",
        "        # Forward Pass\n",
        "        zs = xs.dot(ws) + bs\n",
        "        yhat = sigmoid(zs)\n",
        "\n",
        "        # Loss Calculation\n",
        "        loss = mse(yhat, ys)\n",
        "        if (i)%10 == 0:\n",
        "            print(f\"Epoch: {i+1}, Loss: {loss}\")\n",
        "\n",
        "        # Calculating Gradients\n",
        "        dl_dyhat = mse_grad(yhat, ys)\n",
        "        dyhat_dz = sigmoid_grad(yhat)\n",
        "        dl_dz = dyhat_dz * dl_dyhat\n",
        "        dl_dw = (1/xs.shape[0])*np.dot(xs.T, dl_dz) # dl_dz*dz_dw\n",
        "        dl_db = dl_dz.mean(0) # 1\n",
        "\n",
        "        # Backward Pass\n",
        "        ws += -lr * dl_dw\n",
        "        bs += -lr * dl_db\n",
        "\n",
        "    return ws, bs"
      ],
      "metadata": {
        "id": "I6VlFub5w7Cj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ys = np.random.uniform(low=0, high=1., size=(20,2))\n",
        "xs = np.random.uniform(low= -4, high = 4, size = (20, 3))\n",
        "trained_ws, trained_bs = train(xs, ys, 100)"
      ],
      "metadata": {
        "id": "VTnD8Rt4x8zf",
        "outputId": "ad03fadd-d206-4dcd-9a01-750f673520d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 3) (20, 2) (3, 2) (2,)\n",
            "Epoch: 1, Loss: 0.17480770537172163\n",
            "Epoch: 11, Loss: 0.14914855268778654\n",
            "Epoch: 21, Loss: 0.12973814316934065\n",
            "Epoch: 31, Loss: 0.11517636329801513\n",
            "Epoch: 41, Loss: 0.10321831826716292\n",
            "Epoch: 51, Loss: 0.09272226704806837\n",
            "Epoch: 61, Loss: 0.08349640143061773\n",
            "Epoch: 71, Loss: 0.07582077763916781\n",
            "Epoch: 81, Loss: 0.0699662471142186\n",
            "Epoch: 91, Loss: 0.06588078714386562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3, 4, 2\n",
        "ys = np.random.uniform(low=0, high=1., size=(20,2))\n",
        "xs = np.random.uniform(low= -10, high = 10, size = (20, 3))\n",
        "\n",
        "w1 = np.random.uniform(low = -1, high = 1, size = (xs.shape[1], 4))\n",
        "b1 = np.zeros((4))\n",
        "\n",
        "w2 = np.random.uniform(low = -1, high = 1, size = (4, ys.shape[1]))\n",
        "b2 = np.zeros((ys.shape[1]))\n",
        "\n",
        "z1 = np.dot(xs, w1) + b1\n",
        "a1 = sigmoid(z1)\n",
        "\n",
        "z2 = np.dot(a1, w2) + b2\n",
        "yhat = sigmoid(z2)\n",
        "loss = mse(yhat, ys)\n",
        "\n",
        "print(\"First Loss: \", loss)\n",
        "\n",
        "dl_dyhat = mse_grad(yhat, ys)\n",
        "dl_dyhat.shape\n",
        "\n",
        "dyhat_dz2 = sigmoid_grad(yhat)\n",
        "dyhat_dz2.shape\n",
        "\n",
        "dl_dz2 = dl_dyhat * dyhat_dz2\n",
        "dl_dz2.shape\n",
        "\n",
        "# dl_dw2 = dl_dz2 * dz2_dw2\n",
        "# dl_db2 = dl_dz2\n",
        "\n",
        "dl_dw2 = (1/a1.shape[0]) * np.dot(a1.T, dl_dz2) # Done\n",
        "dl_db2 = dl_dz2.mean(0) # Done\n",
        "\n",
        "dl_dw2.shape, dl_db2.shape\n",
        "\n",
        "# Now we have to calculate dz2_da1\n",
        "# then dl_da1 = dl_dz2 * dz2_da1\n",
        "w2.shape, dl_dz2.shape\n",
        "\n",
        "# dz2_dz1 = w2\n",
        "dl_da1 = np.dot(dl_dz2, w2.T)\n",
        "dl_da1.shape\n",
        "\n",
        "# dl_dz1 = dl_da1 * da1_dz1\n",
        "da1_dz1 = sigmoid_grad(a1)\n",
        "dl_dz1 = dl_da1 * da1_dz1\n",
        "dl_dz1.shape\n",
        "\n",
        "dl_dw1 = (1/z1.shape[0]) * np.dot(xs.T, dl_dz1) # Done\n",
        "dl_db1 = dl_dz1.mean(0) # Done\n",
        "\n",
        "dl_dw1.shape, dl_db1.shape\n",
        "\n",
        "lr = 0.89\n",
        "\n",
        "w1 += -lr * dl_dw1\n",
        "b1 += -lr * dl_db1\n",
        "\n",
        "w2 += -lr * dl_dw2\n",
        "b2 += -lr * dl_db2\n",
        "\n",
        "z1 = np.dot(xs, w1) + b1\n",
        "a1 = sigmoid(z1)\n",
        "\n",
        "z2 = np.dot(a1, w2) + b2\n",
        "yhat = sigmoid(z2)\n",
        "loss = mse(yhat, ys)\n",
        "\n",
        "loss"
      ],
      "metadata": {
        "id": "mWSJW44oSVw_",
        "outputId": "cce16af2-13d6-4fd2-fe90-e59784aa7308",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Loss:  0.08896005403578382\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08859228406828024"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp_train(xs, ys, n_epochs = 100):\n",
        "\n",
        "    lr = 0.7\n",
        "    # 3x2 matrix for 3 inputs and 2 outputs\n",
        "    w1 = np.random.uniform(low = -1, high = 1, size = (xs.shape[1], 4))\n",
        "    b1 = np.zeros((4))\n",
        "\n",
        "    w2 = np.random.uniform(low = -1, high = 1, size = (4, ys.shape[1]))\n",
        "    b2 = np.zeros((ys.shape[1]))\n",
        "\n",
        "    # print(xs.shape, ys.shape, ws.shape, bs.shape)\n",
        "\n",
        "    for i in range(n_epochs):\n",
        "\n",
        "        # Forward Pass\n",
        "        z1 = np.dot(xs, w1) + b1\n",
        "        a1 = relu(z1)\n",
        "\n",
        "        z2 = np.dot(a1, w2) + b2\n",
        "        yhat = sigmoid(z2)\n",
        "\n",
        "        # Loss Calculation\n",
        "        loss = mse(yhat, ys)\n",
        "        if (i)%10 == 0:\n",
        "            print(f\"Epoch: {i+1}, Loss: {loss}\")\n",
        "\n",
        "        # Calculating Gradients\n",
        "        dl_dyhat = mse_grad(yhat, ys)\n",
        "        dyhat_dz2 = sigmoid_grad(yhat)\n",
        "\n",
        "        dl_dz2 = dl_dyhat * dyhat_dz2\n",
        "\n",
        "        # Activation to weight\n",
        "        dl_dw2 = (1/a1.shape[0]) * np.dot(a1.T, dl_dz2) # Done\n",
        "        dl_db2 = dl_dz2.mean(0) # Done\n",
        "\n",
        "        # Activation to Activation\n",
        "        dl_da1 = np.dot(dl_dz2, w2.T)\n",
        "        da1_dz1 = relu_grad(z1)\n",
        "\n",
        "        dl_dz1 = dl_da1 * da1_dz1\n",
        "\n",
        "        dl_dw1 = (1/z1.shape[0]) * np.dot(xs.T, dl_dz1) # Done\n",
        "        dl_db1 = dl_dz1.mean(0) # Done\n",
        "\n",
        "        # Backward Pass\n",
        "        w1 += -lr * dl_dw1\n",
        "        b1 += -lr * dl_db1\n",
        "\n",
        "        w2 += -lr * dl_dw2\n",
        "        b2 += -lr * dl_db2\n",
        "\n",
        "    return w1, b1, w2, b2"
      ],
      "metadata": {
        "id": "WQ6zugpVSl42"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ys = np.random.uniform(low=0, high=1., size=(20,2))\n",
        "xs = np.random.uniform(low= -4, high = 4, size = (20, 3))\n",
        "mlp_parameters = mlp_train(xs, ys, 200)"
      ],
      "metadata": {
        "id": "i3QBeH5ITzt4",
        "outputId": "6f7824a8-38c5-4cff-ebe6-505128b417a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.20880276427291705\n",
            "Epoch: 11, Loss: 0.19286537214136576\n",
            "Epoch: 21, Loss: 0.17876130479920377\n",
            "Epoch: 31, Loss: 0.1684445768804895\n",
            "Epoch: 41, Loss: 0.16049987459064366\n",
            "Epoch: 51, Loss: 0.15302545114742697\n",
            "Epoch: 61, Loss: 0.1460114353910063\n",
            "Epoch: 71, Loss: 0.13947239740666803\n",
            "Epoch: 81, Loss: 0.13341236039021864\n",
            "Epoch: 91, Loss: 0.12781272182953737\n",
            "Epoch: 101, Loss: 0.12263763136945331\n",
            "Epoch: 111, Loss: 0.11781626826874629\n",
            "Epoch: 121, Loss: 0.11331716968269956\n",
            "Epoch: 131, Loss: 0.10911714064164271\n",
            "Epoch: 141, Loss: 0.1051894469078983\n",
            "Epoch: 151, Loss: 0.10149579563690976\n",
            "Epoch: 161, Loss: 0.09801162402526392\n",
            "Epoch: 171, Loss: 0.09472338810090418\n",
            "Epoch: 181, Loss: 0.09159211982221711\n",
            "Epoch: 191, Loss: 0.08874235951211558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zs = torch.randn([2, 3], requires_grad = True)\n",
        "ys = torch.tensor([[0, 1, 0], [1, 0, 0]], dtype = torch.float32)"
      ],
      "metadata": {
        "id": "dpHKJQMIT6Rg"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = F.softmax(zs, dim = 1)\n",
        "yhat, yhat.shape"
      ],
      "metadata": {
        "id": "aZ4HJxQwbBMY",
        "outputId": "cacb1b55-af9c-4604-bc0f-2d7e92d22a27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.3702, 0.3669, 0.2629],\n",
              "         [0.0279, 0.6735, 0.2986]], grad_fn=<SoftmaxBackward0>),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = F.cross_entropy(yhat, ys)\n",
        "loss"
      ],
      "metadata": {
        "id": "5Ns1KNEcbOyF",
        "outputId": "94d33f95-24a3-4344-89eb-594184c9bf97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.2528, grad_fn=<DivBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "Qms56mOJbXTP"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zs.grad"
      ],
      "metadata": {
        "id": "9KTFqm2zblmw",
        "outputId": "9f8f76d8-d766-465b-c145-0f674a52d087",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0683, -0.0734,  0.0051],\n",
              "        [-0.1198,  0.1011,  0.0187]])"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = zs.clone()"
      ],
      "metadata": {
        "id": "29A2zLWebvPM"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zs = inp.detach().numpy()\n",
        "zs"
      ],
      "metadata": {
        "id": "G2_5RIC6bmgM",
        "outputId": "3d05a2d4-9638-41f4-8431-ac467b1ec10c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.2684945 ,  1.2596434 ,  0.92624325],\n",
              "       [-1.1967338 ,  1.9883913 ,  1.1748823 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = softmax(zs)\n",
        "yhat"
      ],
      "metadata": {
        "id": "zSIhvBfWbxfU",
        "outputId": "870d0b58-ee88-4751-aef3-38cca9679a34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3701842 , 0.36692217, 0.26289365],\n",
              "       [0.0278668 , 0.67354906, 0.29858416]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = cross_entropy(yhat, ys)"
      ],
      "metadata": {
        "id": "JoW7GWYccB70"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "id": "2O2xM6DDjvDX",
        "outputId": "ac0e934b-2cd3-4416-d49d-00862778128b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 1.0026, 0.0000],\n",
              "        [3.5803, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.log(yhat)"
      ],
      "metadata": {
        "id": "7NpQy1Cteo4y",
        "outputId": "0e56344c-1eaa-4eeb-eee9-a343a9dd48f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.9937545 , -1.0026056 , -1.3360057 ],\n",
              "       [-3.5803194 , -0.39519444, -1.2087034 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.log(yhat), ys"
      ],
      "metadata": {
        "id": "4TIhfpl7fXsV",
        "outputId": "be91b45a-aabe-4c13-90d5-aa7dbb36d401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.43588704, -1.8801389 , -1.6057433 ],\n",
              "        [-0.96458936, -0.7107091 , -2.0591323 ]], dtype=float32),\n",
              " tensor([[0., 1., 0.],\n",
              "         [1., 0., 0.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(yhat, y):\n",
        "    return y * -1 * np.log(yhat)"
      ],
      "metadata": {
        "id": "ce-KnXDpepU_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}