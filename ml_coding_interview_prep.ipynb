{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOItM75+ZUPOT3KwxaTuQZ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranay8297/fastaip2/blob/main/ml_coding_interview_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "bXqQT21Q_pNE"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "8Gdx0OTZeraI"
      },
      "outputs": [],
      "source": [
        "# Lets start with Micro grad\n",
        "\n",
        "class Value:\n",
        "\n",
        "    def __init__(self, val, parents = (), op = None, label = None):\n",
        "        self.val = val\n",
        "        self.parents = parents\n",
        "        self.op = op\n",
        "        self.grad = 0\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'Value: {self.val:.4f}' + (f'  :: Label: {self.label}' if self.label != None else '')\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        return self + (-other)\n",
        "\n",
        "    def __neg__(self):\n",
        "        return self * -1\n",
        "\n",
        "    def __radd__(self, other):\n",
        "        return self + other\n",
        "\n",
        "    def __rmul__(self, other):\n",
        "        return self * other\n",
        "\n",
        "    def __truediv__(self, other):\n",
        "        return self * (other**-1)\n",
        "\n",
        "    def __add__(self, other):\n",
        "\n",
        "        if not isinstance(other, Value): other = Value(other, label = str(other))\n",
        "\n",
        "        out = Value(self.val + other.val, (self, other), label = f'{self.label}+{other.label}')\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += 1 * out.grad\n",
        "            other.grad += 1 * out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        if not isinstance(other, Value): other = Value(other, label = str(other))\n",
        "        out = Value(self.val * other.val, (self, other), label = f'{self.label}*{other.label}')\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += other.val * out.grad\n",
        "            other.grad += self.val * out.grad\n",
        "\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def __pow__(self, pow):\n",
        "        out = Value(self.val ** pow, (self,), label = f'{self.label}**{pow}')\n",
        "        def _backward():\n",
        "            self.grad += pow*self.val**(pow-1) * out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def exp(self):\n",
        "        exp = np.exp(self.val)\n",
        "        out = Value(exp, (self,), label = f'exp({self.label})')\n",
        "        def _backward():\n",
        "            self.grad += exp * out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def relu(self):\n",
        "        out = Value(self.val if self.val > 0 else 0, label = f'relu({self.label})')\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += 0 if out.val else out.grad\n",
        "\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def backward(self):\n",
        "        self.grad = 1.\n",
        "        visited = set()\n",
        "        dfs = []\n",
        "        # breakpoint()\n",
        "        def _dfs(node):\n",
        "\n",
        "            if node in visited: return\n",
        "\n",
        "            visited.add(node)\n",
        "\n",
        "            for i in node.parents:\n",
        "                _dfs(i)\n",
        "\n",
        "            dfs.append(node)\n",
        "\n",
        "        _dfs(self)\n",
        "        topsort = reversed(dfs)\n",
        "\n",
        "        for i in topsort:\n",
        "            if not hasattr(i, '_backward'): continue\n",
        "            i._backward()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1, x2 = Value(-1.5, label = 'x1'), Value(1.3, label = 'x2')\n",
        "w1, w2 = Value(4, label = 'w1'), Value(5, label = 'w2')\n",
        "b = Value(0, label = 'b')\n",
        "z = w1*x1 + w2*x2 + b\n",
        "z.label = 'z'\n",
        "\n",
        "# z.backward()\n",
        "# w1.grad, w2.grad, b.grad\n",
        "print(z)\n",
        "yhat = ((2*z).exp() - 1)/((2*z).exp() + 1)\n",
        "# yhat.label = 'yhat'\n",
        "print(yhat)\n",
        "\n",
        "yhat.backward()\n",
        "\n",
        "yhat.grad, z.grad, w1.grad, w2.grad, b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2d0W0kJ5cWA",
        "outputId": "c3ef32d5-c2d1-497b-f55f-38f93b3e3f6f"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value: 0.5000  :: Label: z\n",
            "Value: 0.4621  :: Label: exp(z*2)+-1*exp(z*2)+1**-1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0,\n",
              " 0.7864477329659272,\n",
              " -1.1796715994488909,\n",
              " 1.0223820528557053,\n",
              " 0.7864477329659272)"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Module:\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "class Neuron(Module):\n",
        "    def __init__(self, n_in):\n",
        "        self.ws = [Value(random.uniform(-1, 1)) for _ in range(n_in)]\n",
        "        self.b = Value(0)\n",
        "\n",
        "    def forward(self, x): # dot product + b: wx + b\n",
        "        # breakpoint()\n",
        "        return sum((a * b for a, b in zip(self.ws, x))) + self.b\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Neuron containing: {self.ws}\"\n",
        "\n",
        "class Layer(Module):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        # n_in: number of inputs\n",
        "        # n_out: number of outputs desired in a layer\n",
        "        self.neurons = [Neuron(n_in) for _ in range(n_out)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        return [n(x) for n in self.neurons]\n",
        "\n",
        "    def __repr__(self): return f\"Layer containing weights of shape: {len(self.neurons)}x{len(self.neurons[0].ws)}\"\n",
        "\n",
        "\n",
        "class MLP(Module):\n",
        "\n",
        "    def __init__(self, lc = [], act = 'relu'):\n",
        "        # assume lc - layer_config has n_in preppended\n",
        "        self.layers = [Layer(lc[i-1], lc[i]) for i in range(1, len(lc))]\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def __repr__(self):\n",
        "        st = ''\n",
        "        for i in self.layers:\n",
        "            st += i.__repr__() + ' \\n'\n",
        "        return st"
      ],
      "metadata": {
        "id": "YlIK6eZ_vsqO"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [Value(1, label = 'x1'), Value(1.5, label = 'x2'), Value(1.2, label = 'x3')]\n",
        "neu = Neuron(3)\n",
        "neu(x)"
      ],
      "metadata": {
        "id": "Cv1wZC7lXFhv",
        "outputId": "88c456c4-aa36-42d5-980f-a0b92b887707",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value: -1.1044  :: Label: None*x1+0+None*x2+None*x3+None"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [Value(1, label = 'x1'), Value(1.5, label = 'x2'), Value(1.2, label = 'x3')]\n",
        "layer = Layer(3, 2)\n",
        "inter = layer(x)\n",
        "inter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKorQi6YvTDJ",
        "outputId": "30699cc9-0552-4fe7-ad76-471375f8b13d"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Value: 1.2700  :: Label: None*x1+0+None*x2+None*x3+None,\n",
              " Value: 1.3024  :: Label: None*x1+0+None*x2+None*x3+None]"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [Value(1, label = 'x1'), Value(1.5, label = 'x2'), Value(1.2, label = 'x3')]\n",
        "mlp = MLP((3, 2, 1))\n",
        "yhat = mlp(x)"
      ],
      "metadata": {
        "id": "BDlts59jzruj"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat[0].backward()\n",
        "yhat[0].val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdcRQehVRuSG",
        "outputId": "6c21dfee-d9e0-4325-e87f-efa04c59558a"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.13525551427592739"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in mlp.layers:\n",
        "    for neu in layer.neurons:\n",
        "        print([i.grad for i in neu.ws])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukRREvcE0ehM",
        "outputId": "c8c2780a-9099-4a2a-91ca-b2965ab5f88d"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.29952624858971144, 0.44928937288456716, 0.3594314983076537]\n",
            "[-0.5134056657947423, -0.7701084986921135, -0.6160867989536908]\n",
            "[-0.5655506771842844, -0.06650054863652788]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NhF_apPQVDpN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}